{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.model_selection as skl\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# device11\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0             60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1             20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2             60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3             70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4             60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...          ...      ...          ...      ...    ...   ...      ...   \n",
       "1455          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1456          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1457          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1458          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1459          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities LotConfig  ... PoolArea PoolQC  Fence MiscFeature  \\\n",
       "0            Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
       "1            Lvl    AllPub       FR2  ...        0    NaN    NaN         NaN   \n",
       "2            Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
       "3            Lvl    AllPub    Corner  ...        0    NaN    NaN         NaN   \n",
       "4            Lvl    AllPub       FR2  ...        0    NaN    NaN         NaN   \n",
       "...          ...       ...       ...  ...      ...    ...    ...         ...   \n",
       "1455         Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
       "1456         Lvl    AllPub    Inside  ...        0    NaN  MnPrv         NaN   \n",
       "1457         Lvl    AllPub    Inside  ...        0    NaN  GdPrv        Shed   \n",
       "1458         Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
       "1459         Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
       "\n",
       "     MiscVal MoSold  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0          0      2    2008        WD         Normal     208500  \n",
       "1          0      5    2007        WD         Normal     181500  \n",
       "2          0      9    2008        WD         Normal     223500  \n",
       "3          0      2    2006        WD        Abnorml     140000  \n",
       "4          0     12    2008        WD         Normal     250000  \n",
       "...      ...    ...     ...       ...            ...        ...  \n",
       "1455       0      8    2007        WD         Normal     175000  \n",
       "1456       0      2    2010        WD         Normal     210000  \n",
       "1457    2500      5    2010        WD         Normal     266500  \n",
       "1458       0      4    2010        WD         Normal     142125  \n",
       "1459       0      6    2008        WD         Normal     147500  \n",
       "\n",
       "[1460 rows x 80 columns]"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"./train.csv\")\n",
    "df_test = pd.read_csv(\"./test.csv\")\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_train = df_train.drop(columns=['Id'])\n",
    "\n",
    "# df_test = df_test.reset_index(drop=True)\n",
    "# df_test = df_test.drop(columns=['Id'])\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
       "        'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
       "        'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
       "        'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
       "        'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
       "        'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
       "        'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
       "        'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
       "        'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
       "        'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
       "        'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
       "        'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
       "        'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
       "        'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
       "        'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
       "        'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
       "        'SaleCondition'],\n",
       "       dtype='object'),\n",
       " (80,))"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns, df_test.columns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning\n",
    "cols_dropped = []\n",
    "\n",
    "# train\n",
    "for col in df_train.columns:\n",
    "    nan_percentage = (df_train[col].isna()==True).sum() * 100 / df_train.shape[0]\n",
    "    if nan_percentage > 60.0:\n",
    "        cols_dropped.insert(len(cols_dropped),col)\n",
    "        df_train = df_train.drop(col, axis=1)\n",
    "\n",
    "# test\n",
    "for col in cols_dropped:\n",
    "    df_test = df_test.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0             60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1             20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "2             60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3             70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4             60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "...          ...      ...          ...      ...    ...      ...         ...   \n",
       "1455          60       RL         62.0     7917   Pave      Reg         Lvl   \n",
       "1456          20       RL         85.0    13175   Pave      Reg         Lvl   \n",
       "1457          70       RL         66.0     9042   Pave      Reg         Lvl   \n",
       "1458          20       RL         68.0     9717   Pave      Reg         Lvl   \n",
       "1459          20       RL         75.0     9937   Pave      Reg         Lvl   \n",
       "\n",
       "     Utilities LotConfig LandSlope  ... EnclosedPorch 3SsnPorch ScreenPorch  \\\n",
       "0       AllPub    Inside       Gtl  ...             0         0           0   \n",
       "1       AllPub       FR2       Gtl  ...             0         0           0   \n",
       "2       AllPub    Inside       Gtl  ...             0         0           0   \n",
       "3       AllPub    Corner       Gtl  ...           272         0           0   \n",
       "4       AllPub       FR2       Gtl  ...             0         0           0   \n",
       "...        ...       ...       ...  ...           ...       ...         ...   \n",
       "1455    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "1456    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "1457    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "1458    AllPub    Inside       Gtl  ...           112         0           0   \n",
       "1459    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "\n",
       "     PoolArea MiscVal  MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
       "0           0       0       2    2008        WD         Normal    208500  \n",
       "1           0       0       5    2007        WD         Normal    181500  \n",
       "2           0       0       9    2008        WD         Normal    223500  \n",
       "3           0       0       2    2006        WD        Abnorml    140000  \n",
       "4           0       0      12    2008        WD         Normal    250000  \n",
       "...       ...     ...     ...     ...       ...            ...       ...  \n",
       "1455        0       0       8    2007        WD         Normal    175000  \n",
       "1456        0       0       2    2010        WD         Normal    210000  \n",
       "1457        0    2500       5    2010        WD         Normal    266500  \n",
       "1458        0       0       4    2010        WD         Normal    142125  \n",
       "1459        0       0       6    2008        WD         Normal    147500  \n",
       "\n",
       "[1460 rows x 76 columns]"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# handling categorical value\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# TRAIN\n",
    "le = LabelEncoder()\n",
    "for col in df_train.columns:\n",
    "#     print(df_train[col].dtype)\n",
    "    if(df_train[col].dtype == \"object\"):\n",
    "        df_train[col]=df_train[col].astype(str)\n",
    "        df_train[col] = le.fit_transform(df_train[col])\n",
    "    elif(df_train[col].dtype == \"int\"):\n",
    "        df_train[col]=df_train[col].astype(float)\n",
    "        df_train[col] = le.fit_transform(df_train[col])\n",
    "    else:\n",
    "        df_train[col].fillna(0,inplace=True)\n",
    "        \n",
    "\n",
    "df_train=df_train.astype(float)\n",
    "print(df_train.isnull().sum().sum())\n",
    "\n",
    "df_train = torch.tensor(np.array(df_train), dtype=torch.float32)\n",
    "\n",
    "# TEST\n",
    "for col in df_test.columns:\n",
    "    if(col==\"Id\"): continue\n",
    "#     print(df_test[col].dtype)\n",
    "    if(df_test[col].dtype == \"object\"):\n",
    "        df_test[col]=df_test[col].astype(str)\n",
    "        df_test[col] = le.fit_transform(df_test[col])\n",
    "    elif(df_test[col].dtype == \"int\"):\n",
    "        df_test[col]=df_test[col].astype(float)\n",
    "        df_test[col] = le.fit_transform(df_test[col])\n",
    "    else:\n",
    "        df_test[col].fillna(0,inplace=True)\n",
    "\n",
    "df_test=df_test.astype(float)\n",
    "print(df_test.isnull().sum().sum())\n",
    "df_test.to_csv(\"new_df_test.csv\")\n",
    "\n",
    "df_test = torch.tensor(np.array(df_test), dtype=torch.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  5.,   3.,  65.,  ...,   8.,   4., 412.],\n",
       "        [  0.,   3.,  80.,  ...,   8.,   4., 339.],\n",
       "        [  5.,   3.,  68.,  ...,   8.,   4., 442.],\n",
       "        ...,\n",
       "        [  6.,   3.,  66.,  ...,   8.,   4., 527.],\n",
       "        [  0.,   3.,  68.,  ...,   8.,   4., 199.],\n",
       "        [  0.,   3.,  75.,  ...,   8.,   4., 221.]])"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        \n",
    "        # Adding the first hidden layer and its activation\n",
    "        layers.append(nn.Linear(input_size, hidden_sizes[0]))\n",
    "        layers.append(nn.ReLU())\n",
    "        \n",
    "        # Adding the subsequent hidden layers and their activations\n",
    "        for i in range(1, len(hidden_sizes)):\n",
    "            layers.append(nn.Linear(hidden_sizes[i-1], hidden_sizes[i]))\n",
    "            layers.append(nn.ReLU())\n",
    "        \n",
    "        # Adding the output layer\n",
    "        layers.append(nn.Linear(hidden_sizes[-1], num_classes))\n",
    "        \n",
    "        # Combining all layers into a sequential container\n",
    "        self.all_layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward_propagation(self, x):\n",
    "        return self.all_layers(x)\n",
    "\n",
    "    def compute_l2_loss(self, w):\n",
    "          return torch.square(w).sum()\n",
    "\n",
    "def one_hot_vec(index, cols, rows):\n",
    "    res = torch.zeros(rows, cols)\n",
    "    for i in range(index.shape[0]):\n",
    "        res[i,index[i]]=1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Loss: tensor([314.5057])\n",
      "Epoch [2/300], Loss: tensor([256.1664])\n",
      "Epoch [3/300], Loss: tensor([166.8314])\n",
      "Epoch [4/300], Loss: tensor([126.8241])\n",
      "Epoch [5/300], Loss: tensor([114.8746])\n",
      "Epoch [6/300], Loss: tensor([107.0676])\n",
      "Epoch [7/300], Loss: tensor([99.7493])\n",
      "Epoch [8/300], Loss: tensor([94.4554])\n",
      "Epoch [9/300], Loss: tensor([90.1988])\n",
      "Epoch [10/300], Loss: tensor([86.6249])\n",
      "Epoch [11/300], Loss: tensor([83.8693])\n",
      "Epoch [12/300], Loss: tensor([81.4554])\n",
      "Epoch [13/300], Loss: tensor([79.6984])\n",
      "Epoch [14/300], Loss: tensor([78.1917])\n",
      "Epoch [15/300], Loss: tensor([77.0359])\n",
      "Epoch [16/300], Loss: tensor([75.8992])\n",
      "Epoch [17/300], Loss: tensor([75.0326])\n",
      "Epoch [18/300], Loss: tensor([74.1753])\n",
      "Epoch [19/300], Loss: tensor([73.5203])\n",
      "Epoch [20/300], Loss: tensor([72.8412])\n",
      "Epoch [21/300], Loss: tensor([72.2626])\n",
      "Epoch [22/300], Loss: tensor([71.6567])\n",
      "Epoch [23/300], Loss: tensor([71.1379])\n",
      "Epoch [24/300], Loss: tensor([70.6036])\n",
      "Epoch [25/300], Loss: tensor([70.1114])\n",
      "Epoch [26/300], Loss: tensor([69.6105])\n",
      "Epoch [27/300], Loss: tensor([69.1744])\n",
      "Epoch [28/300], Loss: tensor([68.7311])\n",
      "Epoch [29/300], Loss: tensor([68.3257])\n",
      "Epoch [30/300], Loss: tensor([67.9104])\n",
      "Epoch [31/300], Loss: tensor([67.5188])\n",
      "Epoch [32/300], Loss: tensor([67.1276])\n",
      "Epoch [33/300], Loss: tensor([66.7548])\n",
      "Epoch [34/300], Loss: tensor([66.4010])\n",
      "Epoch [35/300], Loss: tensor([66.0720])\n",
      "Epoch [36/300], Loss: tensor([65.7456])\n",
      "Epoch [37/300], Loss: tensor([65.4305])\n",
      "Epoch [38/300], Loss: tensor([65.1230])\n",
      "Epoch [39/300], Loss: tensor([64.8254])\n",
      "Epoch [40/300], Loss: tensor([64.5052])\n",
      "Epoch [41/300], Loss: tensor([64.2224])\n",
      "Epoch [42/300], Loss: tensor([63.9517])\n",
      "Epoch [43/300], Loss: tensor([63.6815])\n",
      "Epoch [44/300], Loss: tensor([63.4364])\n",
      "Epoch [45/300], Loss: tensor([63.1874])\n",
      "Epoch [46/300], Loss: tensor([62.9572])\n",
      "Epoch [47/300], Loss: tensor([62.7160])\n",
      "Epoch [48/300], Loss: tensor([62.4907])\n",
      "Epoch [49/300], Loss: tensor([62.2736])\n",
      "Epoch [50/300], Loss: tensor([62.0474])\n",
      "Epoch [51/300], Loss: tensor([61.8361])\n",
      "Epoch [52/300], Loss: tensor([61.6151])\n",
      "Epoch [53/300], Loss: tensor([61.4323])\n",
      "Epoch [54/300], Loss: tensor([61.2259])\n",
      "Epoch [55/300], Loss: tensor([61.0094])\n",
      "Epoch [56/300], Loss: tensor([60.8314])\n",
      "Epoch [57/300], Loss: tensor([60.6588])\n",
      "Epoch [58/300], Loss: tensor([60.4629])\n",
      "Epoch [59/300], Loss: tensor([60.2725])\n",
      "Epoch [60/300], Loss: tensor([60.1035])\n",
      "Epoch [61/300], Loss: tensor([59.9595])\n",
      "Epoch [62/300], Loss: tensor([59.8023])\n",
      "Epoch [63/300], Loss: tensor([59.6580])\n",
      "Epoch [64/300], Loss: tensor([59.5168])\n",
      "Epoch [65/300], Loss: tensor([59.3745])\n",
      "Epoch [66/300], Loss: tensor([59.2329])\n",
      "Epoch [67/300], Loss: tensor([59.0936])\n",
      "Epoch [68/300], Loss: tensor([58.9657])\n",
      "Epoch [69/300], Loss: tensor([58.8468])\n",
      "Epoch [70/300], Loss: tensor([58.7654])\n",
      "Epoch [71/300], Loss: tensor([58.6152])\n",
      "Epoch [72/300], Loss: tensor([58.5005])\n",
      "Epoch [73/300], Loss: tensor([58.4113])\n",
      "Epoch [74/300], Loss: tensor([58.2918])\n",
      "Epoch [75/300], Loss: tensor([58.1977])\n",
      "Epoch [76/300], Loss: tensor([58.0808])\n",
      "Epoch [77/300], Loss: tensor([57.9639])\n",
      "Epoch [78/300], Loss: tensor([57.8631])\n",
      "Epoch [79/300], Loss: tensor([57.7511])\n",
      "Epoch [80/300], Loss: tensor([57.6538])\n",
      "Epoch [81/300], Loss: tensor([57.5290])\n",
      "Epoch [82/300], Loss: tensor([57.4346])\n",
      "Epoch [83/300], Loss: tensor([57.3431])\n",
      "Epoch [84/300], Loss: tensor([57.2156])\n",
      "Epoch [85/300], Loss: tensor([57.1277])\n",
      "Epoch [86/300], Loss: tensor([57.0222])\n",
      "Epoch [87/300], Loss: tensor([56.9206])\n",
      "Epoch [88/300], Loss: tensor([56.8142])\n",
      "Epoch [89/300], Loss: tensor([56.7274])\n",
      "Epoch [90/300], Loss: tensor([56.6145])\n",
      "Epoch [91/300], Loss: tensor([56.5113])\n",
      "Epoch [92/300], Loss: tensor([56.4172])\n",
      "Epoch [93/300], Loss: tensor([56.2923])\n",
      "Epoch [94/300], Loss: tensor([56.1853])\n",
      "Epoch [95/300], Loss: tensor([56.0854])\n",
      "Epoch [96/300], Loss: tensor([55.9677])\n",
      "Epoch [97/300], Loss: tensor([55.8800])\n",
      "Epoch [98/300], Loss: tensor([55.7603])\n",
      "Epoch [99/300], Loss: tensor([55.6271])\n",
      "Epoch [100/300], Loss: tensor([55.5343])\n",
      "Epoch [101/300], Loss: tensor([55.4092])\n",
      "Epoch [102/300], Loss: tensor([55.2779])\n",
      "Epoch [103/300], Loss: tensor([55.1778])\n",
      "Epoch [104/300], Loss: tensor([55.0520])\n",
      "Epoch [105/300], Loss: tensor([54.9270])\n",
      "Epoch [106/300], Loss: tensor([54.7979])\n",
      "Epoch [107/300], Loss: tensor([54.6683])\n",
      "Epoch [108/300], Loss: tensor([54.5226])\n",
      "Epoch [109/300], Loss: tensor([54.3453])\n",
      "Epoch [110/300], Loss: tensor([54.1885])\n",
      "Epoch [111/300], Loss: tensor([54.0347])\n",
      "Epoch [112/300], Loss: tensor([53.8904])\n",
      "Epoch [113/300], Loss: tensor([53.7081])\n",
      "Epoch [114/300], Loss: tensor([53.5608])\n",
      "Epoch [115/300], Loss: tensor([53.4023])\n",
      "Epoch [116/300], Loss: tensor([53.2573])\n",
      "Epoch [117/300], Loss: tensor([53.1013])\n",
      "Epoch [118/300], Loss: tensor([52.9689])\n",
      "Epoch [119/300], Loss: tensor([52.8186])\n",
      "Epoch [120/300], Loss: tensor([52.6728])\n",
      "Epoch [121/300], Loss: tensor([52.5310])\n",
      "Epoch [122/300], Loss: tensor([52.4481])\n",
      "Epoch [123/300], Loss: tensor([52.2919])\n",
      "Epoch [124/300], Loss: tensor([52.1730])\n",
      "Epoch [125/300], Loss: tensor([51.9899])\n",
      "Epoch [126/300], Loss: tensor([51.8814])\n",
      "Epoch [127/300], Loss: tensor([51.7374])\n",
      "Epoch [128/300], Loss: tensor([51.5943])\n",
      "Epoch [129/300], Loss: tensor([51.4644])\n",
      "Epoch [130/300], Loss: tensor([51.3206])\n",
      "Epoch [131/300], Loss: tensor([51.1912])\n",
      "Epoch [132/300], Loss: tensor([51.0566])\n",
      "Epoch [133/300], Loss: tensor([50.9861])\n",
      "Epoch [134/300], Loss: tensor([50.8418])\n",
      "Epoch [135/300], Loss: tensor([50.7472])\n",
      "Epoch [136/300], Loss: tensor([50.6023])\n",
      "Epoch [137/300], Loss: tensor([50.5073])\n",
      "Epoch [138/300], Loss: tensor([50.3564])\n",
      "Epoch [139/300], Loss: tensor([50.3002])\n",
      "Epoch [140/300], Loss: tensor([50.1756])\n",
      "Epoch [141/300], Loss: tensor([50.0693])\n",
      "Epoch [142/300], Loss: tensor([49.9291])\n",
      "Epoch [143/300], Loss: tensor([49.8042])\n",
      "Epoch [144/300], Loss: tensor([49.6550])\n",
      "Epoch [145/300], Loss: tensor([49.5453])\n",
      "Epoch [146/300], Loss: tensor([49.4161])\n",
      "Epoch [147/300], Loss: tensor([49.3286])\n",
      "Epoch [148/300], Loss: tensor([49.2847])\n",
      "Epoch [149/300], Loss: tensor([49.2154])\n",
      "Epoch [150/300], Loss: tensor([49.1074])\n",
      "Epoch [151/300], Loss: tensor([48.9629])\n",
      "Epoch [152/300], Loss: tensor([48.8231])\n",
      "Epoch [153/300], Loss: tensor([48.7200])\n",
      "Epoch [154/300], Loss: tensor([48.5953])\n",
      "Epoch [155/300], Loss: tensor([48.4856])\n",
      "Epoch [156/300], Loss: tensor([48.3780])\n",
      "Epoch [157/300], Loss: tensor([48.3247])\n",
      "Epoch [158/300], Loss: tensor([48.1980])\n",
      "Epoch [159/300], Loss: tensor([48.1288])\n",
      "Epoch [160/300], Loss: tensor([48.0915])\n",
      "Epoch [161/300], Loss: tensor([47.9222])\n",
      "Epoch [162/300], Loss: tensor([47.8922])\n",
      "Epoch [163/300], Loss: tensor([47.7593])\n",
      "Epoch [164/300], Loss: tensor([47.6621])\n",
      "Epoch [165/300], Loss: tensor([47.5892])\n",
      "Epoch [166/300], Loss: tensor([47.4460])\n",
      "Epoch [167/300], Loss: tensor([47.3527])\n",
      "Epoch [168/300], Loss: tensor([47.2395])\n",
      "Epoch [169/300], Loss: tensor([47.1742])\n",
      "Epoch [170/300], Loss: tensor([47.0618])\n",
      "Epoch [171/300], Loss: tensor([46.9720])\n",
      "Epoch [172/300], Loss: tensor([46.9704])\n",
      "Epoch [173/300], Loss: tensor([46.8660])\n",
      "Epoch [174/300], Loss: tensor([46.7884])\n",
      "Epoch [175/300], Loss: tensor([46.7279])\n",
      "Epoch [176/300], Loss: tensor([46.6770])\n",
      "Epoch [177/300], Loss: tensor([46.5607])\n",
      "Epoch [178/300], Loss: tensor([46.4864])\n",
      "Epoch [179/300], Loss: tensor([46.4806])\n",
      "Epoch [180/300], Loss: tensor([46.3773])\n",
      "Epoch [181/300], Loss: tensor([46.2920])\n",
      "Epoch [182/300], Loss: tensor([46.3645])\n",
      "Epoch [183/300], Loss: tensor([46.2373])\n",
      "Epoch [184/300], Loss: tensor([46.1663])\n",
      "Epoch [185/300], Loss: tensor([46.1130])\n",
      "Epoch [186/300], Loss: tensor([46.0281])\n",
      "Epoch [187/300], Loss: tensor([46.0053])\n",
      "Epoch [188/300], Loss: tensor([45.9186])\n",
      "Epoch [189/300], Loss: tensor([45.8517])\n",
      "Epoch [190/300], Loss: tensor([45.8004])\n",
      "Epoch [191/300], Loss: tensor([45.7189])\n",
      "Epoch [192/300], Loss: tensor([45.6501])\n",
      "Epoch [193/300], Loss: tensor([45.5053])\n",
      "Epoch [194/300], Loss: tensor([45.4841])\n",
      "Epoch [195/300], Loss: tensor([45.3851])\n",
      "Epoch [196/300], Loss: tensor([45.3730])\n",
      "Epoch [197/300], Loss: tensor([45.3574])\n",
      "Epoch [198/300], Loss: tensor([45.2659])\n",
      "Epoch [199/300], Loss: tensor([45.1812])\n",
      "Epoch [200/300], Loss: tensor([45.1516])\n",
      "Epoch [201/300], Loss: tensor([45.0576])\n",
      "Epoch [202/300], Loss: tensor([44.9125])\n",
      "Epoch [203/300], Loss: tensor([44.8404])\n",
      "Epoch [204/300], Loss: tensor([44.7985])\n",
      "Epoch [205/300], Loss: tensor([44.7366])\n",
      "Epoch [206/300], Loss: tensor([44.6197])\n",
      "Epoch [207/300], Loss: tensor([44.6467])\n",
      "Epoch [208/300], Loss: tensor([44.5235])\n",
      "Epoch [209/300], Loss: tensor([44.4461])\n",
      "Epoch [210/300], Loss: tensor([44.4117])\n",
      "Epoch [211/300], Loss: tensor([44.3648])\n",
      "Epoch [212/300], Loss: tensor([44.2357])\n",
      "Epoch [213/300], Loss: tensor([44.2546])\n",
      "Epoch [214/300], Loss: tensor([44.1840])\n",
      "Epoch [215/300], Loss: tensor([44.0580])\n",
      "Epoch [216/300], Loss: tensor([44.0036])\n",
      "Epoch [217/300], Loss: tensor([43.9469])\n",
      "Epoch [218/300], Loss: tensor([43.8816])\n",
      "Epoch [219/300], Loss: tensor([43.8311])\n",
      "Epoch [220/300], Loss: tensor([43.7438])\n",
      "Epoch [221/300], Loss: tensor([43.7034])\n",
      "Epoch [222/300], Loss: tensor([43.6506])\n",
      "Epoch [223/300], Loss: tensor([43.5714])\n",
      "Epoch [224/300], Loss: tensor([43.6288])\n",
      "Epoch [225/300], Loss: tensor([43.4911])\n",
      "Epoch [226/300], Loss: tensor([43.4413])\n",
      "Epoch [227/300], Loss: tensor([43.3977])\n",
      "Epoch [228/300], Loss: tensor([43.3137])\n",
      "Epoch [229/300], Loss: tensor([43.2032])\n",
      "Epoch [230/300], Loss: tensor([43.1654])\n",
      "Epoch [231/300], Loss: tensor([43.0895])\n",
      "Epoch [232/300], Loss: tensor([43.1065])\n",
      "Epoch [233/300], Loss: tensor([43.0050])\n",
      "Epoch [234/300], Loss: tensor([43.0248])\n",
      "Epoch [235/300], Loss: tensor([42.8538])\n",
      "Epoch [236/300], Loss: tensor([42.8101])\n",
      "Epoch [237/300], Loss: tensor([42.7388])\n",
      "Epoch [238/300], Loss: tensor([42.6787])\n",
      "Epoch [239/300], Loss: tensor([42.5826])\n",
      "Epoch [240/300], Loss: tensor([42.5891])\n",
      "Epoch [241/300], Loss: tensor([42.5065])\n",
      "Epoch [242/300], Loss: tensor([42.4245])\n",
      "Epoch [243/300], Loss: tensor([42.3922])\n",
      "Epoch [244/300], Loss: tensor([42.2987])\n",
      "Epoch [245/300], Loss: tensor([42.2022])\n",
      "Epoch [246/300], Loss: tensor([42.1842])\n",
      "Epoch [247/300], Loss: tensor([42.1499])\n",
      "Epoch [248/300], Loss: tensor([42.0954])\n",
      "Epoch [249/300], Loss: tensor([42.0192])\n",
      "Epoch [250/300], Loss: tensor([42.0470])\n",
      "Epoch [251/300], Loss: tensor([41.9338])\n",
      "Epoch [252/300], Loss: tensor([41.9542])\n",
      "Epoch [253/300], Loss: tensor([41.8152])\n",
      "Epoch [254/300], Loss: tensor([41.7631])\n",
      "Epoch [255/300], Loss: tensor([41.7337])\n",
      "Epoch [256/300], Loss: tensor([41.6512])\n",
      "Epoch [257/300], Loss: tensor([41.6387])\n",
      "Epoch [258/300], Loss: tensor([41.5781])\n",
      "Epoch [259/300], Loss: tensor([41.5273])\n",
      "Epoch [260/300], Loss: tensor([41.5047])\n",
      "Epoch [261/300], Loss: tensor([41.4639])\n",
      "Epoch [262/300], Loss: tensor([41.3802])\n",
      "Epoch [263/300], Loss: tensor([41.3830])\n",
      "Epoch [264/300], Loss: tensor([41.3452])\n",
      "Epoch [265/300], Loss: tensor([41.2354])\n",
      "Epoch [266/300], Loss: tensor([41.2101])\n",
      "Epoch [267/300], Loss: tensor([41.1750])\n",
      "Epoch [268/300], Loss: tensor([41.1114])\n",
      "Epoch [269/300], Loss: tensor([41.1193])\n",
      "Epoch [270/300], Loss: tensor([41.0207])\n",
      "Epoch [271/300], Loss: tensor([41.0189])\n",
      "Epoch [272/300], Loss: tensor([41.0231])\n",
      "Epoch [273/300], Loss: tensor([40.9126])\n",
      "Epoch [274/300], Loss: tensor([40.8745])\n",
      "Epoch [275/300], Loss: tensor([40.8231])\n",
      "Epoch [276/300], Loss: tensor([40.8337])\n",
      "Epoch [277/300], Loss: tensor([40.7845])\n",
      "Epoch [278/300], Loss: tensor([40.8149])\n",
      "Epoch [279/300], Loss: tensor([40.6878])\n",
      "Epoch [280/300], Loss: tensor([40.6247])\n",
      "Epoch [281/300], Loss: tensor([40.6496])\n",
      "Epoch [282/300], Loss: tensor([40.5926])\n",
      "Epoch [283/300], Loss: tensor([40.5705])\n",
      "Epoch [284/300], Loss: tensor([40.4780])\n",
      "Epoch [285/300], Loss: tensor([40.4923])\n",
      "Epoch [286/300], Loss: tensor([40.4642])\n",
      "Epoch [287/300], Loss: tensor([40.4350])\n",
      "Epoch [288/300], Loss: tensor([40.3402])\n",
      "Epoch [289/300], Loss: tensor([40.3163])\n",
      "Epoch [290/300], Loss: tensor([40.2963])\n",
      "Epoch [291/300], Loss: tensor([40.2380])\n",
      "Epoch [292/300], Loss: tensor([40.2444])\n",
      "Epoch [293/300], Loss: tensor([40.1681])\n",
      "Epoch [294/300], Loss: tensor([40.1562])\n",
      "Epoch [295/300], Loss: tensor([40.0858])\n",
      "Epoch [296/300], Loss: tensor([40.0754])\n",
      "Epoch [297/300], Loss: tensor([40.0483])\n",
      "Epoch [298/300], Loss: tensor([39.9910])\n",
      "Epoch [299/300], Loss: tensor([39.9746])\n",
      "Epoch [300/300], Loss: tensor([39.9057])\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "input_size = 75\n",
    "hidden_sizes = [32,16,8]\n",
    "output_y = 1\n",
    "num_epochs = 300\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "weight_decay = 1e-5\n",
    "\n",
    "\n",
    "# model\n",
    "model = NeuralNet(input_size, hidden_sizes, output_y).to(device)\n",
    "\n",
    "# loss and optimizer\n",
    "loss_fn = nn.MSELoss(reduction=\"sum\")\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "losses = []\n",
    "\n",
    "# data loader for iteration\n",
    "train_loader = torch.utils.data.DataLoader(dataset=df_train,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "\n",
    "# Train model\n",
    "total_steps = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # each iteration will give a batch of points \n",
    "    tot_avg_loss = 0\n",
    "    \n",
    "    for i,data in enumerate(train_loader): \n",
    "        points = data[:, 0:75].clone().detach().float().to(device)\n",
    "        outputs = data[:,75].clone().detach().float().reshape(-1,1).to(device)\n",
    "\n",
    "        # forward prop\n",
    "        outputs_ = model.forward_propagation(points)\n",
    "        loss = loss_fn(outputs_, outputs)\n",
    "        \n",
    "        # Compute l2 loss component\n",
    "        l2_weight = 1.0\n",
    "        l2_parameters = []\n",
    "        for parameter in model.parameters():\n",
    "            l2_parameters.append(parameter.view(-1))\n",
    "        l2 = l2_weight * model.compute_l2_loss(torch.cat(l2_parameters))\n",
    "      \n",
    "        # Add l2 loss component\n",
    "        loss += l2\n",
    "\n",
    "        # backward prop and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        tot_avg_loss += loss.item()\n",
    "\n",
    "    \n",
    "    tot_avg_loss /= train_loader.dataset.shape[0] \n",
    "    tot_avg_loss = torch.sqrt(torch.Tensor([tot_avg_loss])) \n",
    "    losses.append(tot_avg_loss.item())\n",
    "    \n",
    "    print (f'Epoch [{epoch+1}/{num_epochs}], Loss: {tot_avg_loss}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABVzUlEQVR4nO3deVxU5eI/8M/srDMjwjCgCIom7hma0qLeJHHJNO2WZqnV1TKszGzxdjO1bqTt5VZ30eqrLfZLS3MJ95uRqWmaGqmpaLIoyC7DLM/vD5gjI6iAzDk4fN6v17xgzjlz5jkPg3x8tqMSQggQERER+Si10gUgIiIi8iaGHSIiIvJpDDtERETk0xh2iIiIyKcx7BAREZFPY9ghIiIin8awQ0RERD6NYYeIiIh8GsMOERER+TSGHSKFjB8/HjExMfV67cyZM6FSqRq2QES1tGXLFqhUKmzZskXpohDVCsMO0UVUKlWtHk31H/rx48cjKChI6WL4jCVLlkClUmHXrl3StjVr1mDmzJnKFarSggULsGTJEqWLQXTVVLw3FpGn//u///N4/vHHHyM1NRWffPKJx/bbb78d4eHh9X4fu90Ol8sFg8FQ59c6HA44HA74+fnV+/3ra/z48fjyyy9RXFws+3v7oiVLluDBBx/Ezp070aNHDwDA5MmTMX/+fCj9z3Pnzp0RGhpaLdi7XC6Ul5dDr9dDreb/manx0ypdAKLG5v777/d4/uOPPyI1NbXa9ouVlpYiICCg1u+j0+nqVT4A0Gq10Gr563utKCkpQWBgoKJlEEKgrKwM/v7+V30utVqtSNAmqi9GcqJ66NevHzp37ozdu3ejT58+CAgIwN///ncAwNdff40hQ4YgMjISBoMBsbGxePnll+F0Oj3OcfGYnePHj0OlUuGNN97Ahx9+iNjYWBgMBvTs2RM7d+70eG1NY3ZUKhUmT56MlStXonPnzjAYDOjUqRPWrVtXrfxbtmxBjx494Ofnh9jYWHzwwQcNPg5o+fLliI+Ph7+/P0JDQ3H//ffjzz//9DgmKysLDz74IFq2bAmDwYCIiAgMGzYMx48fl47ZtWsXkpKSEBoaCn9/f7Ru3RoPPfRQrcqwYMECdOrUCQaDAZGRkUhOTkZ+fr60f/LkyQgKCkJpaWm1144ePRpWq9Xj57Z27VrceuutCAwMRHBwMIYMGYIDBw54vM7dzXf06FEMHjwYwcHBGDNmTK3K6379/PnzAXh2qbq5XC6888476NSpE/z8/BAeHo5HHnkE586d8zhPTEwM7rjjDqxfvx49evSAv78/PvjgAwDA4sWLcdttt8FiscBgMKBjx45YuHBhtdcfOHAAW7dulcrQr18/AJces1Obn7m7fv78808MHz4cQUFBCAsLw7Rp06r9jnz22WeIj49HcHAwjEYjunTpgnfffbfWdUnkxv8aEtVTbm4uBg0ahFGjRuH++++XurSWLFmCoKAgTJ06FUFBQdi0aRNmzJiBwsJCvP7661c877Jly1BUVIRHHnkEKpUKc+fOxYgRI/DHH39csTXo+++/x1dffYXHHnsMwcHBeO+99zBy5EhkZGSgefPmAIA9e/Zg4MCBiIiIwKxZs+B0OjF79myEhYVdfaVUcnfN9OzZEykpKcjOzsa7776L7du3Y8+ePTCbzQCAkSNH4sCBA3j88ccRExODnJwcpKamIiMjQ3o+YMAAhIWF4fnnn4fZbMbx48fx1VdfXbEMM2fOxKxZs5CYmIhJkyYhPT0dCxcuxM6dO7F9+3bodDrce++9mD9/Pr799lv89a9/lV5bWlqKVatWYfz48dBoNACATz75BOPGjUNSUhLmzJmD0tJSLFy4ELfccgv27NnjEVwdDgeSkpJwyy234I033qhTi98jjzyC06dP19h16t7vrt8nnngCx44dw7x587Bnzx7putzS09MxevRoPPLII5gwYQLat28PAFi4cCE6deqEO++8E1qtFqtWrcJjjz0Gl8uF5ORkAMA777yDxx9/HEFBQXjhhRcA4LLdtrX9mQOA0+lEUlISevXqhTfeeAMbNmzAm2++idjYWEyaNAkAkJqaitGjR6N///6YM2cOAODQoUPYvn07nnzyyVrXJxEAQBDRZSUnJ4uLf1X69u0rAIhFixZVO760tLTatkceeUQEBASIsrIyadu4ceNEdHS09PzYsWMCgGjevLnIy8uTtn/99dcCgFi1apW07aWXXqpWJgBCr9eLI0eOSNt++eUXAUC8//770rahQ4eKgIAA8eeff0rbDh8+LLRabbVz1mTcuHEiMDDwkvvLy8uFxWIRnTt3FufPn5e2r169WgAQM2bMEEIIce7cOQFAvP7665c814oVKwQAsXPnziuWq6qcnByh1+vFgAEDhNPplLbPmzdPABD//e9/hRBCuFwu0aJFCzFy5EiP13/xxRcCgNi2bZsQQoiioiJhNpvFhAkTPI7LysoSJpPJY/u4ceMEAPH888/XqqyLFy+udo01feaEEOJ///ufACCWLl3qsX3dunXVtkdHRwsAYt26ddXOU9NnNCkpSbRp08ZjW6dOnUTfvn2rHbt582YBQGzevFkIUfufuRAX6mf27Nke5+zevbuIj4+Xnj/55JPCaDQKh8NR7f2J6ordWET1ZDAY8OCDD1bbXnVMRFFREc6ePYtbb70VpaWl+O2336543nvvvRfNmjWTnt96660AgD/++OOKr01MTERsbKz0vGvXrjAajdJrnU4nNmzYgOHDhyMyMlI6rm3bthg0aNAVz18bu3btQk5ODh577DGPcR1DhgxBXFwcvv32WwAV9aTX67Fly5ZqXTBu7taA1atXw26317oMGzZsQHl5OaZMmeIxgHbChAkwGo1SGVQqFf76179izZo1HgOuP//8c7Ro0QK33HILgIpWhvz8fIwePRpnz56VHhqNBr169cLmzZurlcHdQtGQli9fDpPJhNtvv92jHPHx8QgKCqpWjtatWyMpKanaeap+RgsKCnD27Fn07dsXf/zxBwoKCupcrtr+zKt69NFHPZ7feuutHp9xs9mMkpISpKam1rk8RBdj2CGqpxYtWkCv11fbfuDAAdx1110wmUwwGo0ICwuTBjfX5g9Jq1atPJ67g8+lAsHlXut+vfu1OTk5OH/+PNq2bVvtuJq21ceJEycAQOoyqSouLk7abzAYMGfOHKxduxbh4eHo06cP5s6di6ysLOn4vn37YuTIkZg1axZCQ0MxbNgwLF68GDabrV5l0Ov1aNOmjbQfqAiX58+fxzfffAMAKC4uxpo1a/DXv/5VGitz+PBhAMBtt92GsLAwj8d3332HnJwcj/fRarVo2bLllSurjg4fPoyCggJYLJZq5SguLq5WjtatW9d4nu3btyMxMRGBgYEwm80ICwuTxpzVJ+zU9mfu5ufnV63btOrnFAAee+wxXHfddRg0aBBatmyJhx56qMbxZ0S1wTE7RPVU06yW/Px89O3bF0ajEbNnz0ZsbCz8/Pzw888/47nnnoPL5bried1jRC4majEN+Wpeq4QpU6Zg6NChWLlyJdavX48XX3wRKSkp2LRpE7p37w6VSoUvv/wSP/74I1atWoX169fjoYcewptvvokff/yxQdb76d27N2JiYvDFF1/gvvvuw6pVq3D+/Hnce++90jHun9snn3wCq9Va7RwXz4wzGAxemZLtcrlgsViwdOnSGvdfHCBq+owePXoU/fv3R1xcHN566y1ERUVBr9djzZo1ePvtt2v1Gb1al/qcVmWxWLB3716sX78ea9euxdq1a7F48WKMHTsWH330kdfLSL6FYYeoAW3ZsgW5ubn46quv0KdPH2n7sWPHFCzVBRaLBX5+fjhy5Ei1fTVtq4/o6GgAFYNjb7vtNo996enp0n632NhYPP3003j66adx+PBhXH/99XjzzTc91jvq3bs3evfujX/+859YtmwZxowZg88++wx/+9vfrliGNm3aSNvLy8tx7NgxJCYmehx/zz334N1330VhYSE+//xzxMTEoHfv3h5lBCrq7+LXesOlZsXFxsZiw4YNuPnmm+s9hXzVqlWw2Wz45ptvPFoCa+qKq+3svLr+zGtLr9dj6NChGDp0KFwuFx577DF88MEHePHFFxusJZKaBnZjETUg9/9Yq7aklJeXY8GCBUoVyYNGo0FiYiJWrlyJ06dPS9uPHDmCtWvXNsh79OjRAxaLBYsWLfLoblq7di0OHTqEIUOGAKiY8VRWVubx2tjYWAQHB0uvO3fuXLVWqeuvvx4ALtuVlZiYCL1ej/fee8/j9f/5z39QUFAglcHt3nvvhc1mw0cffYR169bhnnvu8diflJQEo9GIV199tcaxQ2fOnLlkWerDvSZP1WnyQEUoczqdePnll6u9xuFwVDu+JjV9RgsKCrB48eIay1Gbc9b2Z14Xubm5Hs/VajW6du0K4PI/e6KasGWHqAHddNNNaNasGcaNG4cnnngCKpUKn3zySaPqRpo5cya+++473HzzzZg0aRKcTifmzZuHzp07Y+/evbU6h91uxyuvvFJte0hICB577DHMmTMHDz74IPr27YvRo0dL05BjYmLw1FNPAQB+//139O/fH/fccw86duwIrVaLFStWIDs7G6NGjQIAfPTRR1iwYAHuuusuxMbGoqioCP/6179gNBoxePDgS5YvLCwM06dPx6xZszBw4EDceeedSE9Px4IFC9CzZ89qC0TecMMNaNu2LV544QXYbDaPLiwAMBqNWLhwIR544AHccMMNGDVqFMLCwpCRkYFvv/0WN998M+bNm1eruquN+Ph4AMATTzyBpKQkaDQajBo1Cn379sUjjzyClJQU7N27FwMGDIBOp8Phw4exfPlyvPvuu7j77rsve+4BAwZILSaPPPIIiouL8a9//QsWiwWZmZnVyrFw4UK88soraNu2LSwWS7WWG6Bigcza/Mzr4m9/+xvy8vJw2223oWXLljhx4gTef/99XH/99ejQoUOdz0dNnIIzwYiuCZeaet6pU6caj9++fbvo3bu38Pf3F5GRkeLZZ58V69ev95iqK8Slp57XNBUbgHjppZek55eaep6cnFzttdHR0WLcuHEe2zZu3Ci6d+8u9Hq9iI2NFf/+97/F008/Lfz8/C5RCxe4pw7X9IiNjZWO+/zzz0X37t2FwWAQISEhYsyYMeLUqVPS/rNnz4rk5GQRFxcnAgMDhclkEr169RJffPGFdMzPP/8sRo8eLVq1aiUMBoOwWCzijjvuELt27bpiOYWomGoeFxcndDqdCA8PF5MmTRLnzp2r8dgXXnhBABBt27a95Pk2b94skpKShMlkEn5+fiI2NlaMHz/eozxXmpp/sZqmnjscDvH444+LsLAwoVKpqv2sP/zwQxEfHy/8/f1FcHCw6NKli3j22WfF6dOnpWOio6PFkCFDanzPb775RnTt2lX4+fmJmJgYMWfOHPHf//5XABDHjh2TjsvKyhJDhgwRwcHBAoA0Df3iqeduV/qZX65+Lv5Mf/nll2LAgAHCYrEIvV4vWrVqJR555BGRmZl52fokqgnvjUVEAIDhw4fjwIED0swjIiJfwTE7RE3Q+fPnPZ4fPnwYa9askW4HQETkS9iyQ9QERUREYPz48dKaMwsXLoTNZsOePXvQrl07pYtHRNSgOECZqAkaOHAgPv30U2RlZcFgMCAhIQGvvvoqgw4R+SS27BAREZFP45gdIiIi8mkMO0REROTTOGYHFfebOX36NIKDg2u9PDoREREpSwiBoqIiREZGXvZ+dAw7AE6fPo2oqCili0FERET1cPLkSbRs2fKS+xl2AAQHBwOoqCyj0ahwaYiIiKg2CgsLERUVJf0dvxSGHVy4s6/RaGTYISIiusZcaQgKBygTERGRT2PYISIiIp/GsENEREQ+jWN2iIhIMU6nE3a7XeliUCOl0+mg0Wiu+jwMO0REJDshBLKyspCfn690UaiRM5vNsFqtV7UOHsMOERHJzh10LBYLAgICuKArVSOEQGlpKXJycgAAERER9T4Xww4REcnK6XRKQad58+ZKF4caMX9/fwBATk4OLBZLvbu0OECZiIhk5R6jExAQoHBJ6Frg/pxczdguhh0iIlIEu66oNhric8KwQ0RERD6NYYeIiEhBMTExeOedd2p9/JYtW6BSqTiTrQ4YdoiIiGpBpVJd9jFz5sx6nXfnzp2YOHFirY+/6aabkJmZCZPJVK/3qy1fClWcjeVFOUVlsNldCAs2wE939YsiERGRcjIzM6XvP//8c8yYMQPp6enStqCgIOl7IQScTie02iv/mQ0LC6tTOfR6PaxWa51e09SxZceL7lmUhlvnbsavfxYoXRQiIrpKVqtVephMJqhUKun5b7/9huDgYKxduxbx8fEwGAz4/vvvcfToUQwbNgzh4eEICgpCz549sWHDBo/zXtyNpVKp8O9//xt33XUXAgIC0K5dO3zzzTfS/otbXJYsWQKz2Yz169ejQ4cOCAoKwsCBAz3CmcPhwBNPPAGz2YzmzZvjueeew7hx4zB8+PB618e5c+cwduxYNGvWDAEBARg0aBAOHz4s7T9x4gSGDh2KZs2aITAwEJ06dcKaNWuk144ZMwZhYWHw9/dHu3btsHjx4nqX5UoYdrxIp6mo3nKnS+GSEBE1bkIIlJY7ZH8IIRr0Op5//nm89tprOHToELp27Yri4mIMHjwYGzduxJ49ezBw4EAMHToUGRkZlz3PrFmzcM8992Dfvn0YPHgwxowZg7y8vEseX1paijfeeAOffPIJtm3bhoyMDEybNk3aP2fOHCxduhSLFy/G9u3bUVhYiJUrV17VtY4fPx67du3CN998g7S0NAghMHjwYGmKeHJyMmw2G7Zt24b9+/djzpw5UuvXiy++iIMHD2Lt2rU4dOgQFi5ciNDQ0Ksqz+WwG8uLtJVhx+Fs2F8mIiJfc97uRMcZ62V/34OzkxCgb7g/hbNnz8btt98uPQ8JCUG3bt2k5y+//DJWrFiBb775BpMnT77kecaPH4/Ro0cDAF599VW89957+OmnnzBw4MAaj7fb7Vi0aBFiY2MBAJMnT8bs2bOl/e+//z6mT5+Ou+66CwAwb948qZWlPg4fPoxvvvkG27dvx0033QQAWLp0KaKiorBy5Ur89a9/RUZGBkaOHIkuXboAANq0aSO9PiMjA927d0ePHj0AVLRueRNbdrxIr6lYG8DhYssOEVFT4P7j7VZcXIxp06ahQ4cOMJvNCAoKwqFDh67YstO1a1fp+8DAQBiNRum2CTUJCAiQgg5QcWsF9/EFBQXIzs7GjTfeKO3XaDSIj4+v07VVdejQIWi1WvTq1Uva1rx5c7Rv3x6HDh0CADzxxBN45ZVXcPPNN+Oll17Cvn37pGMnTZqEzz77DNdffz2effZZ/PDDD/UuS22wZceL3C075Q627BARXY6/ToODs5MUed+GFBgY6PF82rRpSE1NxRtvvIG2bdvC398fd999N8rLyy97Hp1O5/FcpVLBdZn/ONd0fEN30dXV3/72NyQlJeHbb7/Fd999h5SUFLz55pt4/PHHMWjQIJw4cQJr1qxBamoq+vfvj+TkZLzxxhteKQtbdrxIq2bLDhFRbahUKgTotbI/vL2K8/bt2zF+/Hjcdddd6NKlC6xWK44fP+7V97yYyWRCeHg4du7cKW1zOp34+eef633ODh06wOFwYMeOHdK23NxcpKeno2PHjtK2qKgoPProo/jqq6/w9NNP41//+pe0LywsDOPGjcP//d//4Z133sGHH35Y7/JcCVt2vEivrciSdg5QJiJqktq1a4evvvoKQ4cOhUqlwosvvnjZFhpvefzxx5GSkoK2bdsiLi4O77//Ps6dO1ersLd//34EBwdLz1UqFbp164Zhw4ZhwoQJ+OCDDxAcHIznn38eLVq0wLBhwwAAU6ZMwaBBg3Ddddfh3Llz2Lx5Mzp06AAAmDFjBuLj49GpUyfYbDasXr1a2ucNDDte5G7ZsXOAMhFRk/TWW2/hoYcewk033YTQ0FA899xzKCwslL0czz33HLKysjB27FhoNBpMnDgRSUlJtbqLeJ8+fTyeazQaOBwOLF68GE8++STuuOMOlJeXo0+fPlizZo3UpeZ0OpGcnIxTp07BaDRi4MCBePvttwFUrBU0ffp0HD9+HP7+/rj11lvx2WefNfyFV1IJpTv1GoHCwkKYTCYUFBTAaDQ22HknfrwL3x3Mxqt3dcF9vVo12HmJiK5lZWVlOHbsGFq3bg0/Pz+li9MkuVwudOjQAffccw9efvllpYtzWZf7vNT27zdbdrzIvc4Ou7GIiEhJJ06cwHfffYe+ffvCZrNh3rx5OHbsGO677z6liyYLDlD2Iq3G3Y3FsENERMpRq9VYsmQJevbsiZtvvhn79+/Hhg0bvDpOpjFhy44XXWjZafI9hUREpKCoqChs375d6WIohi07XqRzLyrIlh0iIiLFMOx4kdSy42LLDhHRxTg/hmqjIT4nioadhQsXomvXrjAajTAajUhISMDatWul/WVlZUhOTkbz5s0RFBSEkSNHIjs72+McGRkZGDJkCAICAmCxWPDMM8/A4XDIfSk10qo5QJmI6GLuqcmlpaUKl4SuBe7PycWrRNeFomN2WrZsiddeew3t2rWDEAIfffQRhg0bhj179qBTp0546qmn8O2332L58uUwmUyYPHkyRowYIfU7Op1ODBkyBFarFT/88AMyMzMxduxY6HQ6vPrqq0peGgB2YxER1USj0cBsNkv3bgoICPD6SsZ07RFCoLS0FDk5OTCbzbVaE+hSGt06OyEhIXj99ddx9913IywsDMuWLcPdd98NAPjtt9/QoUMHpKWloXfv3li7di3uuOMOnD59GuHh4QCARYsW4bnnnsOZM2eg1+tr9Z7eWmfnjfXpmLf5CMbfFIOZd3ZqsPMSEV3rhBDIyspCfn6+0kWhRs5sNsNqtdYYiK+5dXacTieWL1+OkpISJCQkYPfu3bDb7UhMTJSOiYuLQ6tWraSwk5aWhi5dukhBBwCSkpIwadIkHDhwAN27d1fiUiScek5EVDOVSoWIiAhYLBbY7Xali0ONlE6nu6oWHTfFw87+/fuRkJCAsrIyBAUFYcWKFejYsSP27t0LvV4Ps9nscXx4eDiysrIAAFlZWR5Bx73fve9SbDYbbDab9NxbS3e7Byg7OPWciKhGGo2mQf6YEV2O4rOx2rdvj71792LHjh2YNGkSxo0bh4MHD3r1PVNSUmAymaRHVFSUV95Hx5YdIiIixSkedvR6Pdq2bYv4+HikpKSgW7duePfdd2G1WlFeXl6tPzc7OxtWqxUAYLVaq83Ocj93H1OT6dOno6CgQHqcPHmyYS+qkjQbi1PPiYiIFKN42LmYy+WCzWZDfHw8dDodNm7cKO1LT09HRkYGEhISAAAJCQnYv3+/NKIfAFJTU2E0GtGxY8dLvofBYJCmu7sf3qDTVoYdB1t2iIiIlKLomJ3p06dj0KBBaNWqFYqKirBs2TJs2bIF69evh8lkwsMPP4ypU6ciJCQERqMRjz/+OBISEtC7d28AwIABA9CxY0c88MADmDt3LrKysvCPf/wDycnJMBgMSl4aAECnrpx67mLYISIiUoqiYScnJwdjx45FZmYmTCYTunbtivXr1+P2228HALz99ttQq9UYOXIkbDYbkpKSsGDBAun1Go0Gq1evxqRJk5CQkIDAwECMGzcOs2fPVuqSPPDeWERERMprdOvsKMFb6+x8vfdPPPnZXtwU2xzLJvRusPMSERFR7f9+N7oxO76EU8+JiIiUx7DjRe6wU86p50RERIph2PEi9wrKHKBMRESkHIYdL9KzG4uIiEhxDDtepK2ces5uLCIiIuUw7HiRli07REREimPY8SK9tM4OW3aIiIiUwrDjRVrpRqBs2SEiIlIKw44XSevscDYWERGRYhh2vEjnbtnhjUCJiIgUw7DjRe4BynYXu7GIiIiUwrDjRVLLDgcoExERKYZhx4t06orqFQJwsnWHiIhIEQw7XqTTXqhetu4QEREpg2HHi9wrKAMMO0REREph2PEi99RzgKsoExERKYVhx4s0ahXcjTts2SEiIlIGw46Xcfo5ERGRshh2vEwv3QyULTtERERKYNjxMi3X2iEiIlIUw46XadXuO5+zG4uIiEgJDDtepmfLDhERkaIYdrxMGqDMlh0iIiJFMOx4mfv+WBygTEREpAyGHS/TsWWHiIhIUQw7XibNxnKxZYeIiEgJDDteJrXsOBh2iIiIlMCw42W6yqnnDq6gTEREpAiGHS/TaTn1nIiISEkMO17GRQWJiIiUxbDjZZx6TkREpCyGHS+7MPWcYYeIiEgJDDtexhWUiYiIlMWw42VSNxbX2SEiIlIEw46X6ThAmYiISFEMO16m5V3PiYiIFMWw42UcoExERKQshh0vuzD1nN1YRERESmDY8TLe9ZyIiEhZDDtepmU3FhERkaIYdrxMp+bUcyIiIiUx7HiZTltRxeUOdmMREREpgWHHy7Rs2SEiIlIUw46X6Stbdjgbi4iISBkMO16mrVxBuZwDlImIiBTBsONlWmmdHYYdIiIiJTDseJme6+wQEREpimHHy3hvLCIiImUx7HiZRlURdlyCLTtERERKYNjxMo009Zxhh4iISAkMO17mDjsuhh0iIiJFKBp2UlJS0LNnTwQHB8NisWD48OFIT0/3OKZfv35QqVQej0cffdTjmIyMDAwZMgQBAQGwWCx45pln4HA45LyUS2LLDhERkbK0Sr751q1bkZycjJ49e8LhcODvf/87BgwYgIMHDyIwMFA6bsKECZg9e7b0PCAgQPre6XRiyJAhsFqt+OGHH5CZmYmxY8dCp9Ph1VdflfV6auJeZ8fJsENERKQIRcPOunXrPJ4vWbIEFosFu3fvRp8+faTtAQEBsFqtNZ7ju+++w8GDB7FhwwaEh4fj+uuvx8svv4znnnsOM2fOhF6v9+o1XEll1mHYISIiUkijGrNTUFAAAAgJCfHYvnTpUoSGhqJz586YPn06SktLpX1paWno0qULwsPDpW1JSUkoLCzEgQMHanwfm82GwsJCj4e3SC07nI1FRESkCEVbdqpyuVyYMmUKbr75ZnTu3Fnaft999yE6OhqRkZHYt28fnnvuOaSnp+Orr74CAGRlZXkEHQDS86ysrBrfKyUlBbNmzfLSlXjSsGWHiIhIUY0m7CQnJ+PXX3/F999/77F94sSJ0vddunRBREQE+vfvj6NHjyI2NrZe7zV9+nRMnTpVel5YWIioqKj6FfwKNByzQ0REpKhG0Y01efJkrF69Gps3b0bLli0ve2yvXr0AAEeOHAEAWK1WZGdnexzjfn6pcT4GgwFGo9Hj4S3uRQUZdoiIiJShaNgRQmDy5MlYsWIFNm3ahNatW1/xNXv37gUAREREAAASEhKwf/9+5OTkSMekpqbCaDSiY8eOXil3XbinnjPsEBERKUPRbqzk5GQsW7YMX3/9NYKDg6UxNiaTCf7+/jh69CiWLVuGwYMHo3nz5ti3bx+eeuop9OnTB127dgUADBgwAB07dsQDDzyAuXPnIisrC//4xz+QnJwMg8Gg5OUBYNghIiJSmqItOwsXLkRBQQH69euHiIgI6fH5558DAPR6PTZs2IABAwYgLi4OTz/9NEaOHIlVq1ZJ59BoNFi9ejU0Gg0SEhJw//33Y+zYsR7r8ihJCjucjUVERKQIRVt2xBUCQFRUFLZu3XrF80RHR2PNmjUNVawGJYUdJ8MOERGREhrFAGVfpmXLDhERkaIYdrxMzXtjERERKYphx8u0HKBMRESkKIYdL1NXWWfnSmOUiIiIqOEx7HiZu2UHANi4Q0REJD+GHS/TaC6EHXZlERERyY9hx8vct4sAGHaIiIiUwLDjZZoq3Vicfk5ERCQ/hh0v8wg7XFiQiIhIdgw7XubRjcWWHSIiItkx7HiZWq2CO+84XC5lC0NERNQEMezIwD39nFmHiIhIfgw7MnAvLMiWHSIiIvkx7MiALTtERETKYdiRwYWbgTLtEBERyY1hRwZSyw5nYxEREcmOYUcGGqllh2GHiIhIbgw7MnCHHd4ugoiISH4MOzJwLyzIsENERCQ/hh0ZuO98zm4sIiIi+THsyMDdsuNi2CEiIpIdw44MOECZiIhIOQw7MtCqK6qZLTtERETyY9iRgZotO0RERIph2JGBe1FBJxcVJCIikh3DjgzcLTtOJ8MOERGR3Bh2ZMCWHSIiIuUw7MiAiwoSEREph2FHBrxdBBERkXIYdmTAsENERKQchh0ZMOwQEREph2FHBgw7REREymHYkYGGs7GIiIgUw7AjA/dsLK6gTEREJD+GHRloNO5FBV0Kl4SIiKjpYdiRgbTODht2iIiIZMewIwNpBWUXW3aIiIjkxrAjgwuzsRQuCBERURPEsCMDDVt2iIiIFMOwIwO27BARESmHYUcGbNkhIiJSDsOODLioIBERkXIYdmTARQWJiIiUw7AjA/eigi6GHSIiItkx7MiALTtERETKYdiRgXtRQbbsEBERyY9hRwZqNVt2iIiIlMKwIwOpZYezsYiIiGTHsCMDqWWHdwIlIiKSHcOODLRcZ4eIiEgxioadlJQU9OzZE8HBwbBYLBg+fDjS09M9jikrK0NycjKaN2+OoKAgjBw5EtnZ2R7HZGRkYMiQIQgICIDFYsEzzzwDh8Mh56VcllrlXkGZYYeIiEhuioadrVu3Ijk5GT/++CNSU1Nht9sxYMAAlJSUSMc89dRTWLVqFZYvX46tW7fi9OnTGDFihLTf6XRiyJAhKC8vxw8//ICPPvoIS5YswYwZM5S4pBppOUCZiIhIMSohGk/fypkzZ2CxWLB161b06dMHBQUFCAsLw7Jly3D33XcDAH777Td06NABaWlp6N27N9auXYs77rgDp0+fRnh4OABg0aJFeO6553DmzBno9forvm9hYSFMJhMKCgpgNBob/Lo+STuOF78+gEGdrVh4f3yDn5+IiKgpqu3f70Y1ZqegoAAAEBISAgDYvXs37HY7EhMTpWPi4uLQqlUrpKWlAQDS0tLQpUsXKegAQFJSEgoLC3HgwIEa38dms6GwsNDj4U0adUU1s2WHiIhIfo0m7LhcLkyZMgU333wzOnfuDADIysqCXq+H2Wz2ODY8PBxZWVnSMVWDjnu/e19NUlJSYDKZpEdUVFQDX40nLipIRESknEYTdpKTk/Hrr7/is88+8/p7TZ8+HQUFBdLj5MmTXn0/LipIRESkHK3SBQCAyZMnY/Xq1di2bRtatmwpbbdarSgvL0d+fr5H6052djasVqt0zE8//eRxPvdsLfcxFzMYDDAYDA18FZfGRQWJiIiUo2jLjhACkydPxooVK7Bp0ya0bt3aY398fDx0Oh02btwobUtPT0dGRgYSEhIAAAkJCdi/fz9ycnKkY1JTU2E0GtGxY0d5LuQKuKggERGRchRt2UlOTsayZcvw9ddfIzg4WBpjYzKZ4O/vD5PJhIcffhhTp05FSEgIjEYjHn/8cSQkJKB3794AgAEDBqBjx4544IEHMHfuXGRlZeEf//gHkpOTZW29uRwuKkhERKQcRcPOwoULAQD9+vXz2L548WKMHz8eAPD2229DrVZj5MiRsNlsSEpKwoIFC6RjNRoNVq9ejUmTJiEhIQGBgYEYN24cZs+eLddlXBEXFSQiIlKOomGnNkv8+Pn5Yf78+Zg/f/4lj4mOjsaaNWsasmgNSmrZYdghIiKSXaOZjeXLNAw7REREimHYkQHDDhERkXIYdmTAsENERKQchh0ZaDgbi4iISDEMOzJgyw4REZFyGHZkoJFuF+FSuCRERERND8OODDQq941AFS4IERFRE8SwIwO27BARESmHYUcGF8bsKFwQIiKiJqheYefkyZM4deqU9Pynn37ClClT8OGHHzZYwXzJhRWUmXaIiIjkVq+wc99992Hz5s0AgKysLNx+++346aef8MILLzSqe1I1FpyNRUREpJx6hZ1ff/0VN954IwDgiy++QOfOnfHDDz9g6dKlWLJkSUOWzycw7BARESmnXmHHbrfDYDAAADZs2IA777wTABAXF4fMzMyGK52P4KKCREREyqlX2OnUqRMWLVqE//3vf0hNTcXAgQMBAKdPn0bz5s0btIC+gC07REREyqlX2JkzZw4++OAD9OvXD6NHj0a3bt0AAN98843UvUUXMOwQEREpR1ufF/Xr1w9nz55FYWEhmjVrJm2fOHEiAgICGqxwvkJaVFAAQgioKp8TERGR99WrZef8+fOw2WxS0Dlx4gTeeecdpKenw2KxNGgBfYFWfaGa2bpDREQkr3qFnWHDhuHjjz8GAOTn56NXr1548803MXz4cCxcuLBBC+gLqmQdOBh2iIiIZFWvsPPzzz/j1ltvBQB8+eWXCA8Px4kTJ/Dxxx/jvffea9AC+oKqLTsuzsgiIiKSVb3CTmlpKYKDgwEA3333HUaMGAG1Wo3evXvjxIkTDVpAX8CWHSIiIuXUK+y0bdsWK1euxMmTJ7F+/XoMGDAAAJCTkwOj0digBfQFHi07DDtERESyqlfYmTFjBqZNm4aYmBjceOONSEhIAFDRytO9e/cGLaAvUFeZfMWWHSIiInnVa+r53XffjVtuuQWZmZnSGjsA0L9/f9x1110NVjhfoVKpoFGr4HQJzsYiIiKSWb3CDgBYrVZYrVbp7uctW7bkgoKXoVGp4ATDDhERkdzq1Y3lcrkwe/ZsmEwmREdHIzo6GmazGS+//DJcLldDl9EncBVlIiIiZdSrZeeFF17Af/7zH7z22mu4+eabAQDff/89Zs6cibKyMvzzn/9s0EL6Ai3DDhERkSLqFXY++ugj/Pvf/5budg4AXbt2RYsWLfDYY48x7NRAXRl2OECZiIhIXvXqxsrLy0NcXFy17XFxccjLy7vqQvkid8sOFxUkIiKSV73CTrdu3TBv3rxq2+fNm4euXbtedaF8kdSy42TYISIiklO9urHmzp2LIUOGYMOGDdIaO2lpaTh58iTWrFnToAX0FWzZISIiUka9Wnb69u2L33//HXfddRfy8/ORn5+PESNG4MCBA/jkk08auow+Qa3imB0iIiIl1HudncjIyGoDkX/55Rf85z//wYcffnjVBfM1Wg1nYxERESmhXi07VHcaFcMOERGREhh2ZKKRpp5z0UUiIiI5MezIRK+tqOpyB8MOERGRnOo0ZmfEiBGX3Z+fn381ZfFphsqwY2PYISIiklWdwo7JZLri/rFjx15VgXyVQasBwJYdIiIiudUp7CxevNhb5fB5Bh1bdoiIiJTAMTsyudCN5VS4JERERE0Lw45M3N1YNjtbdoiIiOTEsCMTDlAmIiJSBsOOTC6M2WE3FhERkZwYdmSi11R2Y7Flh4iISFYMOzKRWnY4ZoeIiEhWDDsy4WwsIiIiZTDsyESajcVuLCIiIlkx7MjEwHtjERERKYJhRyacjUVERKQMhh2ZsBuLiIhIGQw7MpEGKHM2FhERkawUDTvbtm3D0KFDERkZCZVKhZUrV3rsHz9+PFQqlcdj4MCBHsfk5eVhzJgxMBqNMJvNePjhh1FcXCzjVdQOZ2MREREpQ9GwU1JSgm7dumH+/PmXPGbgwIHIzMyUHp9++qnH/jFjxuDAgQNITU3F6tWrsW3bNkycONHbRa8zg47dWERERErQKvnmgwYNwqBBgy57jMFggNVqrXHfoUOHsG7dOuzcuRM9evQAALz//vsYPHgw3njjDURGRjZ4metLr+G9sYiIiJTQ6MfsbNmyBRaLBe3bt8ekSZOQm5sr7UtLS4PZbJaCDgAkJiZCrVZjx44dlzynzWZDYWGhx8PbOBuLiIhIGY067AwcOBAff/wxNm7ciDlz5mDr1q0YNGgQnM6KwJCVlQWLxeLxGq1Wi5CQEGRlZV3yvCkpKTCZTNIjKirKq9cBcIAyERGRUhTtxrqSUaNGSd936dIFXbt2RWxsLLZs2YL+/fvX+7zTp0/H1KlTpeeFhYVeDzzuqeflToYdIiIiOTXqlp2LtWnTBqGhoThy5AgAwGq1Iicnx+MYh8OBvLy8S47zASrGARmNRo+Ht7Flh4iISBnXVNg5deoUcnNzERERAQBISEhAfn4+du/eLR2zadMmuFwu9OrVS6li1qjqmB0hhMKlISIiajoU7cYqLi6WWmkA4NixY9i7dy9CQkIQEhKCWbNmYeTIkbBarTh69CieffZZtG3bFklJSQCADh06YODAgZgwYQIWLVoEu92OyZMnY9SoUY1qJhZwoRvLJQCHS0CnUSlcIiIioqZB0ZadXbt2oXv37ujevTsAYOrUqejevTtmzJgBjUaDffv24c4778R1112Hhx9+GPHx8fjf//4Hg8EgnWPp0qWIi4tD//79MXjwYNxyyy348MMPlbqkS3J3YwGcfk5ERCQnRVt2+vXrd9kunfXr11/xHCEhIVi2bFlDFssrPMKO3YkgQ6MeG05EROQzrqkxO9cylUrFhQWJiIgUwLAjowv3x2LYISIikgvDjoy4ijIREZH8GHZkJC0syJYdIiIi2TDsyIjdWERERPJj2JGRnqsoExERyY5hR0YGXUU3FsfsEBERyYdhR0bsxiIiIpIfw46MLoQdtuwQERHJhWFHRu7ZWByzQ0REJB+GHRmxG4uIiEh+DDsyYjcWERGR/Bh2ZCStoMxuLCIiItkw7MhIWkHZybBDREQkF4YdGXHMDhERkfwYdmQkhR07x+wQERHJhWFHRhdWUGbLDhERkVwYdmTEbiwiIiL5MezIiFPPiYiI5MewIyOuoExERCQ/hh0Z6dmNRUREJDuGHRn5VS4qWFruULgkRERETQfDjoxCgwwAgLPF5QqXhIiIqOlg2JFRuNEPAJBdWAYhhMKlISIiahoYdmRkMVa07NgcLhSctytcGiIioqaBYUdGBq0GzQJ0AIDsQpvCpSEiImoaGHZk5u7KyiosU7gkRERETQPDjsyqjtshIiIi72PYkZm1MuzkMOwQERHJgmFHZuGVg5TZjUVERCQPhh2ZWaRuLA5QJiIikgPDjsysHLNDREQkK4YdmXGAMhERkbwYdmQWbqoYs3OmyAani6soExEReRvDjsyaBxqgUavgEsDZYo7bISIi8jaGHZlp1CqEVd4QlF1ZRERE3sewo4BIc8W4nYy8UoVLQkRE5PsYdhTQ1hIEADiSU6xwSYiIiHwfw44C2lmCAQCHGXaIiIi8jmFHAW3DK1p2jjLsEBEReR3DjgLahlWEnT/OlMDhdClcGiIiIt/GsKOAFmZ/+Os0KHe6OEiZiIjIyxh2FKBWq6RByhy3Q0RE5F0MOwrhjCwiIiJ5MOwohGGHiIhIHgw7CmkndWMVKVwSIiIi38awo5CqLTsu3hCUiIjIaxh2FNIqJAB6jRpldhf+zD+vdHGIiIh8FsOOQrQaNdqEBQLguB0iIiJvYthRUCzH7RAREXmdomFn27ZtGDp0KCIjI6FSqbBy5UqP/UIIzJgxAxEREfD390diYiIOHz7scUxeXh7GjBkDo9EIs9mMhx9+GMXF10ZLiTRIOfvaKC8REdG1SNGwU1JSgm7dumH+/Pk17p87dy7ee+89LFq0CDt27EBgYCCSkpJQVlYmHTNmzBgcOHAAqampWL16NbZt24aJEyfKdQlXhTcEJSIi8j6tkm8+aNAgDBo0qMZ9Qgi88847+Mc//oFhw4YBAD7++GOEh4dj5cqVGDVqFA4dOoR169Zh586d6NGjBwDg/fffx+DBg/HGG28gMjJStmupD/eMrKM5xRBCQKVSKVwiIiIi39Nox+wcO3YMWVlZSExMlLaZTCb06tULaWlpAIC0tDSYzWYp6ABAYmIi1Go1duzYcclz22w2FBYWejyUEBMaAI1ahSKbA9mFNkXKQERE5OsabdjJysoCAISHh3tsDw8Pl/ZlZWXBYrF47NdqtQgJCZGOqUlKSgpMJpP0iIqKauDS145Bq0F08wAAwG9ZygQuIiIiX9dow443TZ8+HQUFBdLj5MmTipWlawsTAGBPRr5iZSAiIvJljTbsWK1WAEB2drbH9uzsbGmf1WpFTk6Ox36Hw4G8vDzpmJoYDAYYjUaPh1J6xIQAAHadyFOsDERERL6s0Yad1q1bw2q1YuPGjdK2wsJC7NixAwkJCQCAhIQE5OfnY/fu3dIxmzZtgsvlQq9evWQvc330iGkGoKJlx+F0KVwaIiIi36PobKzi4mIcOXJEen7s2DHs3bsXISEhaNWqFaZMmYJXXnkF7dq1Q+vWrfHiiy8iMjISw4cPBwB06NABAwcOxIQJE7Bo0SLY7XZMnjwZo0aNavQzsdyuswQj2E+LojIHDmUWoUtLk9JFIiIi8imKhp1du3bhL3/5i/R86tSpAIBx48ZhyZIlePbZZ1FSUoKJEyciPz8ft9xyC9atWwc/Pz/pNUuXLsXkyZPRv39/qNVqjBw5Eu+9957s11JfarUKPaKbYXP6Gew8nsewQ0RE1MBUQogmf8vtwsJCmEwmFBQUKDJ+Z/7mI3h9fToGd7FiwZh42d+fiIjoWlTbv9+NdsxOU3Jj64pBymlHc+F0NfnsSURE1KAYdhqB7lFmBPtpca7Ujl9O5StdHCIiIp/CsNMIaDVq9LkuDACw+becKxxNREREdcGw00j8pX3FStCb0xl2iIiIGhLDTiPRr31Fy86vfxYip7DsCkcTERFRbTHsNBKhQQZ0q5x2/t3B7CscTURERLXFsNOIDO4SAQBY9ctphUtCRETkOxh2GpEhXSvCzk/H85BVwK4sIiKihsCw04i0bBaA+OhmEAL4dn+m0sUhIiLyCQw7jcyd3Sru6fXVz6fAxa2JiIiuHsNOIzO0WyQMWjUOnC7ET8fylC4OERHRNY9hp5EJCdRjZHxLAMC//ndM4dIQERFd+xh2GqGHb2kNANj4WzaOnilWuDRERETXNoadRig2LAiJHcIhBDBv0xGli0NERHRNY9hppKYktgMArNz7J47kFClcGiIiomsXw04j1bmFCQM6VrTuvL4+XeniEBERXbMYdhqxqQOug0atwvoD2fh6759KF4eIiOiaxLDTiMVZjXjitorurH+s/BUn80oVLhEREdG1h2GnkUv+Syy6tzKjqMyBCR/vQonNoXSRiIiIrikMO42cVqPG/PtuQGiQAb9lFeHxT/egzO5UulhERETXDIada0Ck2R8fPHAD9Fo1Nv2WgwcX70QxW3iIiIhqhWHnGhEfHYIlD/ZEoF6DtD9yMeZfP+JcSbnSxSIiImr0GHauITfFhuLTib3RLECHX04V4M7532PXcd4/i4iI6HIYdq4xXVuasfzRBLRs5o+TeedxzwdpeH39byh3uJQuGhERUaPEsHMNamsJxponb8WIG1rAJYD5m49i0Lvb8O2+TLhcQuniERERNSoqIUST/+tYWFgIk8mEgoICGI1GpYtTJ2v2Z+KFFftxrtQOAIizBuOp26/DgI7hUKlUCpeOiIjIe2r795thB9d22AGAwjI7/vO/Y/jv98dQVDlLq0sLE6befh36tQ9j6CEiIp/EsFMH13rYccsvLceH2/7Akh+Oo7S8Yi2ezi2MGNs7BkO7RcJfr1G4hERERA2HYacOfCXsuOUW2/DBtj/wcdpxlNkrBi6b/HX4a3xL3N87GjGhgQqXkIiI6Oox7NSBr4Udt9xiG5bvPoX/+/EETp07L23vc10YRveMwl/iLPDTsbWHiIiuTQw7deCrYcfN6RLY+nsOPkk7gS2/n4H7Jx6o1yCxYzju6BqJPteFwqBl8CEiomsHw04d+HrYqSojtxTLfsrAql9O48/8C609wX5aDOhoxR3dInBL21DoNFyVgIiIGjeGnTpoSmHHTQiBPSfzsfqXTHy7/zSyC23SPnOADre1t6B/h3D0uS4UwX46BUtKRERUM4adOmiKYacql0tg14lzWL3vNNbsz8TZ4gv33NJpVOjVujn+EmfBTbHN0T48GGo1p7ITEZHyGHbqoKmHnaqcLoGdx/Ow8VA2Nh7KwR9nSzz2NwvQISG2ORLaNEdCbChiwwK5jg8RESmCYacOGHYu7eiZYmw8lI3tR3Kx83ietH6PmyXYgITY5rgptjl6tW6O6OYBDD9ERCQLhp06YNipnXKHC/tO5SPtaC5+OJqL3Rnnqt2AtFmADtdHmdG9VTNcH2VGtygzTP4c80NERA2PYacOGHbqp8zuxM8Z5/BjZfjZd6oA5c7qd19vExqIjpHGikeEEZ0iTQgLNihQYiIi8iUMO3XAsNMwbA4nDmUWYW/GOew5mY89GfnIyCut8diwYAM6RlQEoDhrMK4LD0absECu9UNERLXGsFMHDDvek1tsw6+nC3HwdCEOZhbi4OkC/HG2BDV96jRqFaKbB6B9eDDahQdXfg1CdPMAhiAiIqqGYacOGHbkVVruwG9ZRVIA+j2rCL9nF6GwzFHj8WoVEBUSgNiwILQJDUTrsEDENA9EdPMARJj8oeFUeCKiJolhpw4YdpQnhEB2oQ2/ZxdJj/TsYhzNKUaxreYQBAB6rRqtQgIQ0zwALZsFINLsh0izPyLN/mhh9kdYkIHrAhER+SiGnTpg2Gm8hBA4U2TDkTPF+ONMCf44U4ITuSU4lluCk3mlsDsv//HVaVQIN/pJ4cdiNCAsyICw4AtfQ4MMMAfoOGWeiOgaU9u/31oZy0RUZyqVChajHyxGP9wUG+qxz+kSOJ1/HsdzS3A8txSn889XeZQhq7AMdqfAqXPnPe76XhOdRoXQIEPlQ1/xNfjC87Aqz83+OrYWERFdQxh26JqlUasQFRKAqJAA3Nqu+n6H04WcIhtO55/Hn5UB6EyRDWeKbThTVIazxeU4U2RDwXk77E6BzIIyZBaU1ep9QwL1HsEoJFCPkEA9mru/BukRElix3einZasREZGCGHbIZ2k1amn8To/LHGdzOJFbGXzOFNlwttiG3JJy6fuKRznOFtuQX2qH0yWkY2tDp1GhWYBnCHKHIndAal4ZnJoHGRiOiIgaGMMONXkGrUYKRVdid7qQWxl83CEot9iGvJJy5JaUV/lqQ15xOUrKnbA7BXKKbMipZTjSa9RoHlQRjNxda+FGA8KNfrAEG2Ax+iHc6IewIAP0WvXVXj4Rkc9j2CGqA51GDavJD1aTX62OL7M7kXdRCMotLvfY5g5LZ4vLUWxzoNzpqnWXWkig/kIACq4MREYDLMEVXxmKiIgYdoi8yk9X+1YjoCIc5ZaU42yRDbklNpwtKseZYhtyCsuQXWhDdlEZcgptyCmqGHztDk2/ZRVd9rxWox9aVY5vigrxR6uQAOkRFmxgtxkR+TSGHaJGxE+nQYvKafKXI4RAfqkd2UUVISinsKyiq+wSoSirsGJ22k/H86qdS69VI8Lkh0iTPyLMVb6a/aXvjX68mSsRXbsaddiZOXMmZs2a5bGtffv2+O233wAAZWVlePrpp/HZZ5/BZrMhKSkJCxYsQHh4uBLFJZKNSqVCs0A9mgXqEWe99HFCVLT+nDp3Hhl5pcjIK8XJyq8ZeRXT9csdLpzILcWJ3JrvYwYAQQYtIs1+iDD5V/nqj0iTHyLM/ogw+cFPx1t6EFHj1KjDDgB06tQJGzZskJ5rtReK/NRTT+Hbb7/F8uXLYTKZMHnyZIwYMQLbt29XoqhEjY5KpULzIAOaBxnQLcpcbb/d6UJWQRlO559HZkEZThecR2Z+xfPTBWXILDiP/FI7im0O/J5djN+ziy/5XiGB+gtBqEoIshortoWbDLzHGREpotGHHa1WC6u1+n9dCwoK8J///AfLli3DbbfdBgBYvHgxOnTogB9//BG9e/eWu6hE1xydRi2tVXQppeUOnM6vCD6Z+RWBSApHlV9Lyy8MxP71z8JLnis0SA+ryQ+WYD+PKfdh0gKOBliCuaI1ETWsRh92Dh8+jMjISPj5+SEhIQEpKSlo1aoVdu/eDbvdjsTEROnYuLg4tGrVCmlpaQw7RA0kQK9FW0sQ2lqCatwvhEDBebsUiE5XhqDsypairMqZZTaHq3K9onIAlw5EFe+pQWiQAc0CdDAHVEzBtxgNVWac+SG8ctYZZ5oR0ZU06rDTq1cvLFmyBO3bt0dmZiZmzZqFW2+9Fb/++iuysrKg1+thNps9XhMeHo6srKzLntdms8Fmu7DmSWHh5f/hJaJLU6lUMAfoYQ7Qo2NkzfemEULgXKldah3KLbFJK1i7Z5+51y46V2pHabmzclzRld4baB5ogNVkuLCSdYAeIUEVizU2C6hYr6hZgB7NAw0I9tPyVh9ETVCjDjuDBg2Svu/atSt69eqF6OhofPHFF/D3r91U3pqkpKRUG/hMRN6jUqmkFaM7RZoue2yZ3YnMgjLkVgafc6UXVrfOLiyrfFyYaeYOSbWhUVesZh0W7L4JbMX3zQL0CPbTIthPh2A/LYx+WgQZdJX72KVGdK1r1GHnYmazGddddx2OHDmC22+/HeXl5cjPz/do3cnOzq5xjE9V06dPx9SpU6XnhYWFiIqK8laxiagO/HQatA4NROvQwMse53IJ5JWWI6ugIgDlFlcs0niutBy5xZVfKxdyPFdSMcja6boQjg5l1q48gXoN/PVaBPtpERZ0ISSFBBoqVrqucj80c4AeZn8dtBp2rRE1JtdU2CkuLsbRo0fxwAMPID4+HjqdDhs3bsTIkSMBAOnp6cjIyEBCQsJlz2MwGGAwGOQoMhF5iVp94U71nVtcvrUIqGgxcgehs8Xu+6BVtBrlny9HUZkDRWX2yq8OFJbZkV9qR0m5EyXlTpwttuHY2ZJalc3kr0NIoB4mfx20ahV0GjVM/joY/bUw+etg8tchyKBFYJVHkEGDQIMWZn89zAE6+Ok0EEJACLDrjegqNeqwM23aNAwdOhTR0dE4ffo0XnrpJWg0GowePRomkwkPP/wwpk6dipCQEBiNRjz++ONISEjg4GQiqsZPp0GEyR8Rptp3gZ8vdyKz4DzK7C4UldlxpjIkVbQiXbj1h7tFKb/UDgAoOG9HwXn7VZZXjXKHCwKAuTI8NQvQVwYjrRSWgvwqglKQQYdAg8Zjn8lfB6vJDzq2NFET16jDzqlTpzB69Gjk5uYiLCwMt9xyC3788UeEhYUBAN5++22o1WqMHDnSY1FBIqKG4K/XoE1YzbPQauJwulBwvmKc0blSO86VlMMlAJvDicLKAFRw3o7C8w4UlztQYqt4FNuclV8dKDhvh9MlUGZ3SeetGLtkB1C7lqWqVCogQKeBXquGQauBQaeGXqOGQadGoF5b2eKkk1qcjH5amAJ0MPrppH1Gv4ogFajnAG+6NqmEEELpQiitsLAQJpMJBQUFMBprnk1CRCQHl0ugqKwi9Bh0aqhUwLkSO/JKypFfWnGz2BKbAyXlThSVOaSQVGxzoLjMgZLyiq/FNgfyS+0od7qu/KZ1EKDXSK1LVb+XuuL0WgRU6ZYLMmgRqHd313keH6DTMDzRVant3+9G3bJDRNTUqNUqmAJ0MAVcuB+ZJdivXudyD+IutTlhczhhc7gqH07Y7C4U2RxSi1Nhmf3C9+cd0raK53a4Kv9bXFruRGm5E2eKajcD7koC9ZrKcKSVWo+CDFUCk17rEZACq23TSMczPNGlMOwQEfko9yBu1L4nrkZCVHSrFdscKC13VLYuXeh6q9jmrNItd6H1yXNb5fNyhxSe3APAGyI8ubvsPFqP9BqPweDuFqeqrU0XWqY8jw/Qa7jsgI9g2CEiostSqVTw12vgr9cAuPqZrFXD04XA5PQISu5wdCFcVQlU0ninyteUOyAEIMSF8JTTQOEpUH9xYNJAr9XA6XLBWLkuk0tU3Cy3WYAezQJ1CNBr4adTw0+rgZ9OU/F95VdDlW0GrQY6jYqBSgYMO0REJKuq4SksuGHC03m7syI02ZxVWpYqAlJp1ZalKuGpakuTx7Yq4ck9HqohwlNN1CpIA8cN2opQZNC6Q1HloPKq23XqKsdftE+rhkGngV/l14v3XThHxdemNEuPYYeIiK5pKpUKAXotAvRaIPjqz1c1PNXUXVfucEGrVqGwcl0mtUqFYpsdeSUVM/BK7U6U2Z2w2Z0os7tQ5qh4XmZ3VWx3XBg07hLAebsT5+3Oqy94HWnUqupBqDJI+VUJYIZLBDDP4y4fzvx0aoQGGRQLWAw7REREVTR0eLqYEKLaYHGboyIMXXh+IRi5B5dXBKjL7HO4YKsMV57nvHBceZWg5XQJacA5cHXrQtVG6lN90C7cCxVaCww7REREMlKpVJXjdjQAdFc8viG5XALlzuqh6OIAVTV4Xdhewz6HC7Zqr/MMce73qrheZTDsEBERNRFqtQp+6oqgZZI5aCmp6YxOIiIioiaJYYeIiIh8GsMOERER+TSGHSIiIvJpDDtERETk0xh2iIiIyKcx7BAREZFPY9ghIiIin8awQ0RERD6NYYeIiIh8GsMOERER+TSGHSIiIvJpDDtERETk0xh2iIiIyKdplS5AYyCEAAAUFhYqXBIiIiKqLfffbfff8Uth2AFQVFQEAIiKilK4JERERFRXRUVFMJlMl9yvEleKQ02Ay+XC6dOnERwcDJVK1WDnLSwsRFRUFE6ePAmj0dhg5/VVrK/aY13VHuuqblhftce6qhtv1JcQAkVFRYiMjIRafemROWzZAaBWq9GyZUuvnd9oNPIXoQ5YX7XHuqo91lXdsL5qj3VVNw1dX5dr0XHjAGUiIiLyaQw7RERE5NMYdrzIYDDgpZdegsFgULoo1wTWV+2xrmqPdVU3rK/aY13VjZL1xQHKRERE5NPYskNEREQ+jWGHiIiIfBrDDhEREfk0hh0iIiLyaQw7XjR//nzExMTAz88PvXr1wk8//aR0kRQ3c+ZMqFQqj0dcXJy0v6ysDMnJyWjevDmCgoIwcuRIZGdnK1hi+Wzbtg1Dhw5FZGQkVCoVVq5c6bFfCIEZM2YgIiIC/v7+SExMxOHDhz2OycvLw5gxY2A0GmE2m/Hwww+juLhYxquQz5Xqa/z48dU+awMHDvQ4pqnUV0pKCnr27Ing4GBYLBYMHz4c6enpHsfU5ncvIyMDQ4YMQUBAACwWC5555hk4HA45L8XralNX/fr1q/bZevTRRz2OaQp1BQALFy5E165dpYUCExISsHbtWml/Y/lcMex4yeeff46pU6fipZdews8//4xu3bohKSkJOTk5ShdNcZ06dUJmZqb0+P7776V9Tz31FFatWoXly5dj69atOH36NEaMGKFgaeVTUlKCbt26Yf78+TXunzt3Lt577z0sWrQIO3bsQGBgIJKSklBWViYdM2bMGBw4cACpqalYvXo1tm3bhokTJ8p1CbK6Un0BwMCBAz0+a59++qnH/qZSX1u3bkVycjJ+/PFHpKamwm63Y8CAASgpKZGOudLvntPpxJAhQ1BeXo4ffvgBH330EZYsWYIZM2YocUleU5u6AoAJEyZ4fLbmzp0r7WsqdQUALVu2xGuvvYbdu3dj165duO222zBs2DAcOHAAQCP6XAnyihtvvFEkJydLz51Op4iMjBQpKSkKlkp5L730kujWrVuN+/Lz84VOpxPLly+Xth06dEgAEGlpaTKVsHEAIFasWCE9d7lcwmq1itdff13alp+fLwwGg/j000+FEEIcPHhQABA7d+6Ujlm7dq1QqVTizz//lK3sSri4voQQYty4cWLYsGGXfE1Trq+cnBwBQGzdulUIUbvfvTVr1gi1Wi2ysrKkYxYuXCiMRqOw2WzyXoCMLq4rIYTo27evePLJJy/5mqZaV27NmjUT//73vxvV54otO15QXl6O3bt3IzExUdqmVquRmJiItLQ0BUvWOBw+fBiRkZFo06YNxowZg4yMDADA7t27YbfbPeotLi4OrVq1avL1duzYMWRlZXnUjclkQq9evaS6SUtLg9lsRo8ePaRjEhMToVarsWPHDtnL3Bhs2bIFFosF7du3x6RJk5Cbmyvta8r1VVBQAAAICQkBULvfvbS0NHTp0gXh4eHSMUlJSSgsLJT+F++LLq4rt6VLlyI0NBSdO3fG9OnTUVpaKu1rqnXldDrx2WefoaSkBAkJCY3qc8UbgXrB2bNn4XQ6PX54ABAeHo7ffvtNoVI1Dr169cKSJUvQvn17ZGZmYtasWbj11lvx66+/IisrC3q9Hmaz2eM14eHhyMrKUqbAjYT7+mv6TLn3ZWVlwWKxeOzXarUICQlpkvU3cOBAjBgxAq1bt8bRo0fx97//HYMGDUJaWho0Gk2TrS+Xy4UpU6bg5ptvRufOnQGgVr97WVlZNX7+3Pt8UU11BQD33XcfoqOjERkZiX379uG5555Deno6vvrqKwBNr67279+PhIQElJWVISgoCCtWrEDHjh2xd+/eRvO5YtghWQ0aNEj6vmvXrujVqxeio6PxxRdfwN/fX8GSka8ZNWqU9H2XLl3QtWtXxMbGYsuWLejfv7+CJVNWcnIyfv31V4+xclSzS9VV1XFdXbp0QUREBPr374+jR48iNjZW7mIqrn379ti7dy8KCgrw5ZdfYty4cdi6davSxfLAbiwvCA0NhUajqTbiPDs7G1arVaFSNU5msxnXXXcdjhw5AqvVivLycuTn53scw3qDdP2X+0xZrdZqA+AdDgfy8vKafP0BQJs2bRAaGoojR44AaJr1NXnyZKxevRqbN29Gy5Ytpe21+d2zWq01fv7c+3zNpeqqJr169QIAj89WU6orvV6Ptm3bIj4+HikpKejWrRvefffdRvW5YtjxAr1ej/j4eGzcuFHa5nK5sHHjRiQkJChYssanuLgYR48eRUREBOLj46HT6TzqLT09HRkZGU2+3lq3bg2r1epRN4WFhdixY4dUNwkJCcjPz8fu3bulYzZt2gSXyyX9Y9yUnTp1Crm5uYiIiADQtOpLCIHJkydjxYoV2LRpE1q3bu2xvza/ewkJCdi/f79HQExNTYXRaETHjh3luRAZXKmuarJ3714A8PhsNYW6uhSXywWbzda4PlcNNtSZPHz22WfCYDCIJUuWiIMHD4qJEycKs9nsMeK8KXr66afFli1bxLFjx8T27dtFYmKiCA0NFTk5OUIIIR599FHRqlUrsWnTJrFr1y6RkJAgEhISFC61PIqKisSePXvEnj17BADx1ltviT179ogTJ04IIYR47bXXhNlsFl9//bXYt2+fGDZsmGjdurU4f/68dI6BAweK7t27ix07dojvv/9etGvXTowePVqpS/Kqy9VXUVGRmDZtmkhLSxPHjh0TGzZsEDfccINo166dKCsrk87RVOpr0qRJwmQyiS1btojMzEzpUVpaKh1zpd89h8MhOnfuLAYMGCD27t0r1q1bJ8LCwsT06dOVuCSvuVJdHTlyRMyePVvs2rVLHDt2THz99deiTZs2ok+fPtI5mkpdCSHE888/L7Zu3SqOHTsm9u3bJ55//nmhUqnEd999J4RoPJ8rhh0vev/990WrVq2EXq8XN954o/jxxx+VLpLi7r33XhERESH0er1o0aKFuPfee8WRI0ek/efPnxePPfaYaNasmQgICBB33XWXyMzMVLDE8tm8ebMAUO0xbtw4IUTF9PMXX3xRhIeHC4PBIPr37y/S09M9zpGbmytGjx4tgoKChNFoFA8++KAoKipS4Gq873L1VVpaKgYMGCDCwsKETqcT0dHRYsKECdX+s9FU6qumegIgFi9eLB1Tm9+948ePi0GDBgl/f38RGhoqnn76aWG322W+Gu+6Ul1lZGSIPn36iJCQEGEwGETbtm3FM888IwoKCjzO0xTqSgghHnroIREdHS30er0ICwsT/fv3l4KOEI3nc6USQoiGayciIiIialw4ZoeIiIh8GsMOERER+TSGHSIiIvJpDDtERETk0xh2iIiIyKcx7BAREZFPY9ghIiIin8awQ0QEICYmBu+8847SxSAiL2DYISLZjR8/HsOHDwcA9OvXD1OmTJHtvZcsWQKz2Vxt+86dOz3uZk1EvkOrdAGIiBpCeXk59Hp9vV8fFhbWgKUhosaELTtEpJjx48dj69atePfdd6FSqaBSqXD8+HEAwK+//opBgwYhKCgI4eHheOCBB3D27Fnptf369cPkyZMxZcoUhIaGIikpCQDw1ltvoUuXLggMDERUVBQee+wxFBcXAwC2bNmCBx98EAUFBdL7zZw5E0D1bqyMjAwMGzYMQUFBMBqNuOeee5CdnS3tnzlzJq6//np88skniImJgclkwqhRo1BUVOTdSiOiOmPYISLFvPvuu0hISMCECROQmZmJzMxMREVFIT8/H7fddhu6d++OXbt2Yd26dcjOzsY999zj8fqPPvoIer0e27dvx6JFiwAAarUa7733Hg4cOICPPvoImzZtwrPPPgsAuOmmm/DOO+/AaDRK7zdt2rRq5XK5XBg2bBjy8vKwdetWpKam4o8//sC9997rcdzRo0excuVKrF69GqtXr8bWrVvx2muveam2iKi+2I1FRIoxmUzQ6/UICAiA1WqVts+bNw/du3fHq6++Km3773//i6ioKPz++++47rrrAADt2rXD3LlzPc5ZdfxPTEwMXnnlFTz66KNYsGAB9Ho9TCYTVCqVx/tdbOPGjdi/fz+OHTuGqKgoAMDHH3+MTp06YefOnejZsyeAilC0ZMkSBAcHAwAeeOABbNy4Ef/85z+vrmKIqEGxZYeIGp1ffvkFmzdvRlBQkPSIi4sDUNGa4hYfH1/ttRs2bED//v3RokULBAcH44EHHkBubi5KS0tr/f6HDh1CVFSUFHQAoGPHjjCbzTh06JC0LSYmRgo6ABAREYGcnJw6XSsReR9bdoio0SkuLsbQoUMxZ86cavsiIiKk7wMDAz32HT9+HHfccQcmTZqEf/7znwgJCcH333+Phx9+GOXl5QgICGjQcup0Oo/nKpUKLperQd+DiK4eww4RKUqv18PpdHpsu+GGG/D//t//Q0xMDLTa2v8ztXv3brhcLrz55ptQqysarr/44osrvt/FOnTogJMnT+LkyZNS687BgweRn5+Pjh071ro8RNQ4sBuLiBQVExODHTt24Pjx4zh79ixcLheSk5ORl5eH0aNHY+fOnTh69CjWr1+PBx988LJBpW3btrDb7Xj//ffxxx9/4JNPPpEGLld9v+LiYmzcuBFnz56tsXsrMTERXbp0wZgxY/Dzzz/jp59+wtixY9G3b1/06NGjweuAiLyLYYeIFDVt2jRoNBp07NgRYWFhyMjIQGRkJLZv3w6n04kBAwagS5cumDJlCsxms9RiU5Nu3brhrbfewpw5c9C5c2csXboUKSkpHsfcdNNNePTRR3HvvfciLCys2gBnoKI76uuvv0azZs3Qp08fJCYmok2bNvj8888b/PqJyPtUQgihdCGIiIiIvIUtO0REROTTGHaIiIjIpzHsEBERkU9j2CEiIiKfxrBDREREPo1hh4iIiHwaww4RERH5NIYdIiIi8mkMO0REROTTGHaIiIjIpzHsEBERkU9j2CEiIiKf9v8BhcuQlg4yuOIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    \n",
    "# Plotting loss\n",
    "plt.figure()\n",
    "plt.plot(range(len(losses)), losses, label='Training Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training Loss over Iterations')\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1459, 76])"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate the model and collect predictions\n",
    "pred_y = []\n",
    "ids = []\n",
    "\n",
    "total_loss = 0\n",
    "\n",
    "# data loader for iteration\n",
    "test_loader = torch.utils.data.DataLoader(dataset=df_test,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader): \n",
    "        iid = data[:,0].clone().detach().float().to(device)\n",
    "        points = data[:, 1:76].clone().detach().float().to(device)\n",
    "\n",
    "        outputs_ = model.forward_propagation(points)\n",
    "        \n",
    "        # Collect data for plotting\n",
    "        ids.append(iid.cpu())\n",
    "        pred_y.append(outputs_.cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [item for tensor in ids for item in tensor.tolist()]\n",
    "pred_y = [item[0] for tensor in pred_y for item in tensor.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {\"Id\": ids, \"SalePrice\": pred_y}\n",
    "res = pd.DataFrame(res)\n",
    "res.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 868283,
     "sourceId": 5407,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
